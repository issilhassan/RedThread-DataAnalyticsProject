# CAHIER DES CHARGES â€“ PROJET DE FIN D'Ã‰TUDES

**Titre :** Analyse PrÃ©dictive et Segmentation ClientÃ¨le dans un Contexte Bancaire  
**Ã‰tudiant :** Hassan Issil  
**FiliÃ¨re :** Master en Business Analytics & Big Data  
**Encadrant :** [Ã€ complÃ©ter]  
**Date :** Janvier 2026  

---

## 1. INTRODUCTION ET CONTEXTE DU PROJET

Dans un environnement bancaire de plus en plus concurrentiel, la rÃ©tention client est devenue une prioritÃ© stratÃ©gique. Le churn (dÃ©sabonnement) entraÃ®ne non seulement une perte de revenus directs, mais aussi une augmentation des coÃ»ts d'acquisition. Les institutions financiÃ¨res disposent aujourd'hui de volumes massifs de donnÃ©es transactionnelles, dÃ©mographiques et comportementales, qu'elles peuvent exploiter via des techniques de Business Intelligence (BI) et de data science pour anticiper les dÃ©parts, personnaliser les offres et optimiser leur relation client.

Ce projet s'inscrit dans cette logique : il vise Ã  transformer des donnÃ©es brutes en insights actionnables, en combinant visualisation interactive, modÃ©lisation statistique et bonnes pratiques ETL. Les donnÃ©es utilisÃ©es sont fictives mais rÃ©alistes (ex. : Churn Modelling, Bank-Customers-Demo), ce qui permet une expÃ©rimentation sans risque sur des cas mÃ©tier pertinents.

---

## 2. PROBLÃ‰MATIQUE MÃ‰TIER

**Comment identifier, comprendre et prÃ©dire les clients Ã  risque de churn afin de mettre en place des actions ciblÃ©es de fidÃ©lisation ?**

Plus prÃ©cisÃ©ment :

- Quels facteurs (gÃ©ographiques, comportementaux, dÃ©mographiques) influencent le plus le dÃ©part d'un client ?
- Peut-on segmenter la clientÃ¨le de maniÃ¨re fine pour adapter la communication marketing ?
- Est-il possible de prÃ©dire la probabilitÃ© de churn avec un modÃ¨le robuste et interprÃ©table ?

---

## 3. OBJECTIFS DU PROJET

### Objectifs principaux
1. RÃ©aliser une analyse exploratoire approfondie des donnÃ©es clients (profils, comportements, tendances)
2. Visualiser les disparitÃ©s de churn par variables clÃ©s (genre, pays, Ã¢ge, produits dÃ©tenus, etc.) via Tableau
3. Construire et Ã©valuer un modÃ¨le de rÃ©gression logistique pour prÃ©dire le churn
4. Segmenter la clientÃ¨le selon des critÃ¨res gÃ©odÃ©mographiques et comportementaux
5. Automatiser un pipeline ETL (Extraction, Transformation, Chargement) pour assurer la reproductibilitÃ©

### Objectifs secondaires
1. Appliquer des tests statistiques (ex. : Ï‡Â²) pour valider la significativitÃ© des liens observÃ©s
2. Ã‰valuer la performance du modÃ¨le via des mÃ©triques pertinentes (CAP Curve, AUC, prÃ©cision, rappel)
3. Documenter l'ensemble du processus dans un repository GitHub propre et structurÃ©

---

## 4. PÃ‰RIMÃˆTRE ET LIVRABLES ATTENDUS

| Livrable | Description | Format |
|----------|-------------|--------|
| **1. Dataset nettoyÃ© et documentÃ©** | DonnÃ©es aprÃ¨s wrangling (gestion des doublons, valeurs manquantes, formats) | CSV + dictionnaire de donnÃ©es |
| **2. Dashboard interactif (Tableau)** | Visualisations clÃ©s : churn par genre/pays/Ã¢ge, segmentation, KPI | Fichier .twb + export PDF |
| **3. ModÃ¨le prÃ©dictif (Python)** | ModÃ¨le de rÃ©gression logistique avec coefficients interprÃ©tÃ©s | Notebook Jupyter + script .py |
| **4. Rapport d'analyse** | InterprÃ©tation mÃ©tier des rÃ©sultats, recommandations | PDF (10â€“15 pages) |
| **5. Repository GitHub** | Code, donnÃ©es, documentation, README clair | Lien public |
| **6. PrÃ©sentation orale** | SynthÃ¨se visuelle des insights et dÃ©monstration du dashboard | PowerPoint / Google Slides |

**âš ï¸ HORS PÃ‰RIMÃˆTRE :** DÃ©ploiement en production, intÃ©gration API temps rÃ©el, machine learning avancÃ© (Random Forest, XGBoost).

---

## 5. MÃ‰THODOLOGIE ET APPROCHE TECHNIQUE

Le projet suit une dÃ©marche **CRISP-DM** (Cross-Industry Standard Process for Data Mining) :

1. **ComprÃ©hension mÃ©tier** â†’ DÃ©finition des questions analytiques
2. **ComprÃ©hension des donnÃ©es** â†’ Exploration, qualitÃ©, distribution
3. **PrÃ©paration des donnÃ©es** â†’ ETL avec Python/SQL incluant :  
   - **Extraction** depuis fichiers CSV  
   - **Transformation** : gestion valeurs manquantes, encodage variables catÃ©gorielles (One-Hot Encoding), normalisation, crÃ©ation de features  
   - **Chargement** : sauvegarde CSV pour Tableau et PostgreSQL (optionnel)
4. **ModÃ©lisation** â†’ Construction d'un modÃ¨le de rÃ©gression logistique (choisi pour son interprÃ©tabilitÃ©) comparÃ© Ã  un classifieur baseline. En parallÃ¨le, segmentation via clustering K-Means sur variables comportementales et dÃ©mographiques
5. **Ã‰valuation** â†’ CAP Curve, matrice de confusion, validation croisÃ©e, mÃ©triques adaptÃ©es au dÃ©sÃ©quilibre des classes
6. **DÃ©ploiement** â†’ Dashboard, rapport, documentation

### Outils & Technologies
- **Langages :** Python (Pandas, Scikit-learn, Matplotlib, Seaborn), SQL
- **BI :** Tableau Desktop (version publique)
- **Base de donnÃ©es :** PostgreSQL (optionnel, pour exercices ETL)
- **Environnement :** Jupyter Notebook, VS Code, Git/GitHub
- **Statistiques :** Test du Ï‡Â², analyse de variance, CAP Curve

---

## 6. PLANNING PRÃ‰VISIONNEL (6 semaines)

| Semaine | ActivitÃ©s |
|---------|-----------|
| **S1** | Audit des datasets, dÃ©finition du scope, initialisation GitHub |
| **S2** | ETL Phase 1 & 2 : nettoyage, gestion erreurs, documentation |
| **S3** | Analyse exploratoire + visualisations Tableau (churn par variable) |
| **S4** | ModÃ©lisation : rÃ©gression logistique, Ã©valuation (CAP, AUC, validation croisÃ©e) |
| **S5** | Segmentation clientÃ¨le (K-Means), tests statistiques, amÃ©lioration dashboard |
| **S6** | RÃ©daction rapport, finalisation livrables, prÃ©paration soutenance |

**âœ… Livraison finale : 10 fÃ©vrier 2026**

---

## 7. CONTRAINTES ET HYPOTHÃˆSES

### Contraintes
- DonnÃ©es fictives â†’ pas de contraintes RGPD, mais rÃ©alisme mÃ©tier exigÃ©
- Outils open source ou versions gratuites (Tableau Public, PostgreSQL)
- Temps limitÃ© (6 semaines) â†’ focus sur la qualitÃ©, pas la complexitÃ© algorithmique

### HypothÃ¨ses
- Les donnÃ©es reflÃ¨tent fidÃ¨lement un contexte bancaire europÃ©en
- Le churn est binaire (parti/restÃ©) et bien dÃ©fini
- Toutes les variables nÃ©cessaires sont disponibles (Ã¢ge, solde, produits, etc.)

---

## 8. INDICATEURS DE SUCCÃˆS ET CRITÃˆRES D'Ã‰VALUATION

Le projet sera jugÃ© sur :

1. **Pertinence mÃ©tier des insights gÃ©nÃ©rÃ©s** (rÃ©ponses aux questions initiales)
2. **QualitÃ© technique** du code, du dashboard et du pipeline ETL
3. **ClartÃ© de la communication** (rapport, prÃ©sentation, documentation GitHub)
4. **Rigueur analytique** (validation statistique, interprÃ©tation des coefficients)
5. **Robustesse de la dÃ©marche** : mÃ©thodologie CRISP-DM suivie et documentÃ©e avec choix techniques justifiÃ©s (gestion dÃ©sÃ©quilibre classes, validation modÃ¨le)

### ğŸ¯ SuccÃ¨s atteint si :
- Le modÃ¨le prÃ©dit le churn avec une **AUC > 0.80**
- Le dashboard permet Ã  un chef de produit de prendre une dÃ©cision en **< 2 minutes**
- Le repository est clonable et reproductible par un pair
- Les **principaux facteurs de churn** sont identifiÃ©s et validÃ©s par l'analyse exploratoire
- Les **segments identifiÃ©s** prÃ©sentent des profils et taux de churn distincts permettant des recommandations marketing diffÃ©renciÃ©es

---

## 9. CONCLUSION

Ce projet constitue une dÃ©monstration concrÃ¨te des compÃ©tences acquises en Business Analytics : de la prÃ©paration des donnÃ©es Ã  la restitution stratÃ©gique. Il allie rigueur statistique, maÃ®trise des outils BI et sens du mÃ©tier, trois piliers essentiels pour tout analyste moderne. Les rÃ©sultats serviront non seulement de support de fin d'Ã©tudes, mais aussi de portfolio professionnel pour des postes en analyse de donnÃ©es, CRM ou intelligence client.

---

## ANNEXE : DATASETS UTILISÃ‰S

1. Churn Modelling (CSV)
2. Bank-Customers-Demo (CSV)
3. FakeNamesUK/Canada (CSV)
4. 50_Startups (CSV)
5. Email Offer (CSV)